{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os, shutil\n",
    "import dv_processing as dv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import helper_funcs as hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing \n",
    "\n",
    "1. Create batches from the recordings. Each batch can be split into `batch_time`.\n",
    "\n",
    "2. Random sample some `N` batches from each subject & letter. Retrieve 5%? of each batch?\n",
    "\n",
    "3. Split into train and test datasets (80 - 20 split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k',\n",
    "           'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', \n",
    "           'v', 'w', 'x', 'y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODE = \"train\"\n",
    "MODE = \"test\"\n",
    "for l in letters:\n",
    "    df = pd.read_csv(f\"../data/{MODE}/{l}.csv\")\n",
    "    df = df.reindex(columns=['x', 'y', 'timestamp', 'polarity'])\n",
    "    starts = df[df['timestamp'] == 0].index\n",
    "\n",
    "    DIR = f'../data/{MODE}/{l}'\n",
    "    if not os.path.isdir(DIR):\n",
    "        os.makedirs(DIR)\n",
    "\n",
    "    for i, t in enumerate(starts):\n",
    "        sample = df.iloc[t:starts[i+1]] if i+1 < len(starts) else df.iloc[t:]\n",
    "        SAVE = f\"{DIR}/test_{l}_{i:04}.bin\"\n",
    "\n",
    "        # Throw out samples with < 1000 events \n",
    "        if len(sample) < 1000:\n",
    "            continue\n",
    "\n",
    "        data = [tuple(row) for row in sample.to_numpy()]\n",
    "        data = np.array(data, dtype=[('x', '<i8'), ('y', '<i8'), ('t', '<i8'), ('p', '<i8')])\n",
    "\n",
    "        with open(SAVE, 'wb') as f:\n",
    "            np.save(f, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "a_0011.bin\n",
      "a_0019.bin\n",
      "a_0024.bin\n",
      "a_0025.bin\n",
      "a_0026.bin\n",
      "a_0029.bin\n",
      "----------\n",
      "\n",
      "b_0002.bin\n",
      "b_0004.bin\n",
      "b_0005.bin\n",
      "b_0006.bin\n",
      "b_0017.bin\n",
      "b_0021.bin\n",
      "b_0027.bin\n",
      "----------\n",
      "\n",
      ".DS_Store\n",
      "c_0007.bin\n",
      "c_0012.bin\n",
      "c_0019.bin\n",
      "c_0020.bin\n",
      "c_0021.bin\n",
      "c_0027.bin\n",
      "----------\n",
      "\n",
      "d_0002.bin\n",
      "d_0010.bin\n",
      "d_0011.bin\n",
      "d_0014.bin\n",
      "d_0016.bin\n",
      "d_0024.bin\n",
      "d_0027.bin\n",
      "----------\n",
      "\n",
      "e_0013.bin\n",
      "e_0016.bin\n",
      "e_0017.bin\n",
      "e_0020.bin\n",
      "e_0023.bin\n",
      "e_0024.bin\n",
      "e_0029.bin\n",
      "----------\n",
      "\n",
      "f_0000.bin\n",
      "f_0001.bin\n",
      "f_0005.bin\n",
      "f_0013.bin\n",
      "f_0016.bin\n",
      "f_0019.bin\n",
      "f_0029.bin\n",
      "----------\n",
      "\n",
      ".DS_Store\n",
      "g_0004.bin\n",
      "g_0005.bin\n",
      "g_0010.bin\n",
      "g_0012.bin\n",
      "g_0017.bin\n",
      "----------\n",
      "\n",
      ".DS_Store\n",
      "h_0003.bin\n",
      "h_0008.bin\n",
      "h_0015.bin\n",
      "h_0019.bin\n",
      "h_0020.bin\n",
      "h_0025.bin\n",
      "----------\n",
      "\n",
      "i_0006.bin\n",
      "i_0007.bin\n",
      "i_0008.bin\n",
      "i_0011.bin\n",
      "i_0018.bin\n",
      "i_0019.bin\n",
      "i_0028.bin\n",
      "----------\n",
      "\n",
      "k_0001.bin\n",
      "k_0010.bin\n",
      "k_0021.bin\n",
      "k_0023.bin\n",
      "k_0024.bin\n",
      "k_0028.bin\n",
      "k_0029.bin\n",
      "----------\n",
      "\n",
      ".DS_Store\n",
      "l_0000.bin\n",
      "l_0007.bin\n",
      "l_0016.bin\n",
      "l_0020.bin\n",
      "l_0026.bin\n",
      "l_0027.bin\n",
      "----------\n",
      "\n",
      ".DS_Store\n",
      "m_0001.bin\n",
      "m_0005.bin\n",
      "m_0012.bin\n",
      "m_0013.bin\n",
      "m_0018.bin\n",
      "m_0022.bin\n",
      "----------\n",
      "\n",
      "n_0013.bin\n",
      "n_0015.bin\n",
      "n_0016.bin\n",
      "n_0017.bin\n",
      "n_0019.bin\n",
      "n_0022.bin\n",
      "n_0027.bin\n",
      "----------\n",
      "\n",
      "o_0002.bin\n",
      "o_0013.bin\n",
      "o_0018.bin\n",
      "o_0020.bin\n",
      "o_0022.bin\n",
      "o_0023.bin\n",
      "o_0028.bin\n",
      "----------\n",
      "\n",
      "p_0009.bin\n",
      "p_0010.bin\n",
      "p_0016.bin\n",
      "p_0021.bin\n",
      "p_0024.bin\n",
      "p_0028.bin\n",
      "p_0029.bin\n",
      "----------\n",
      "\n",
      ".DS_Store\n",
      "q_0004.bin\n",
      "q_0009.bin\n",
      "q_0010.bin\n",
      "q_0013.bin\n",
      "q_0015.bin\n",
      "q_0024.bin\n",
      "----------\n",
      "\n",
      ".DS_Store\n",
      "r_0002.bin\n",
      "r_0005.bin\n",
      "r_0020.bin\n",
      "r_0021.bin\n",
      "r_0023.bin\n",
      "r_0029.bin\n",
      "----------\n",
      "\n",
      ".DS_Store\n",
      "s_0006.bin\n",
      "s_0014.bin\n",
      "s_0015.bin\n",
      "s_0017.bin\n",
      "s_0020.bin\n",
      "s_0023.bin\n",
      "----------\n",
      "\n",
      ".DS_Store\n",
      "t_0003.bin\n",
      "t_0015.bin\n",
      "t_0018.bin\n",
      "t_0019.bin\n",
      "t_0021.bin\n",
      "t_0027.bin\n",
      "----------\n",
      "\n",
      "u_0006.bin\n",
      "u_0014.bin\n",
      "u_0020.bin\n",
      "u_0022.bin\n",
      "u_0023.bin\n",
      "u_0024.bin\n",
      "u_0028.bin\n",
      "----------\n",
      "\n",
      "v_0001.bin\n",
      "v_0004.bin\n",
      "v_0005.bin\n",
      "v_0006.bin\n",
      "v_0007.bin\n",
      "v_0012.bin\n",
      "v_0013.bin\n",
      "----------\n",
      "\n",
      ".DS_Store\n",
      "w_0001.bin\n",
      "w_0004.bin\n",
      "w_0010.bin\n",
      "w_0011.bin\n",
      "w_0018.bin\n",
      "w_0025.bin\n",
      "----------\n",
      "\n",
      "x_0004.bin\n",
      "x_0008.bin\n",
      "x_0011.bin\n",
      "x_0017.bin\n",
      "x_0018.bin\n",
      "x_0027.bin\n",
      "x_0029.bin\n",
      "----------\n",
      "\n",
      "y_0000.bin\n",
      "y_0006.bin\n",
      "y_0013.bin\n",
      "y_0016.bin\n",
      "y_0019.bin\n",
      "y_0020.bin\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DIR = f\"/Users/ria/Documents/GitHub/COSC525_ASL_SNN/data/train\"\n",
    "\n",
    "for l in letters:\n",
    "\n",
    "    D = f\"{DIR}/{l}\"\n",
    "\n",
    "    files = [f for f in sorted(os.listdir(D))]\n",
    "\n",
    "    # Shuffle indices - create train and test sets\n",
    "    idx = np.arange(len(files))\n",
    "    np.random.shuffle(idx)\n",
    "    s = int(len(files) * 0.7)\n",
    "    train = idx[:s]\n",
    "    test = idx[s:]\n",
    "\n",
    "    train = [f for i, f in enumerate(files) if i in train]\n",
    "    test = [f for i, f in enumerate(files) if i in test]\n",
    "\n",
    "    for i, f in enumerate(sorted(os.listdir(D))):\n",
    "\n",
    "        if f in test:\n",
    "            print(f)\n",
    "\n",
    "    print('----------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['file', 'label'])\n",
    "\n",
    "labs = 0\n",
    "prev = []\n",
    "\n",
    "for f in sorted(os.listdir(\"../data/train\")):\n",
    "\n",
    "    label = f.split('_')[0]\n",
    "    \n",
    "    if label not in prev:\n",
    "        prev.append(label)\n",
    "        labs += 1\n",
    "\n",
    "    path = f\"./data/train/{f}\"\n",
    "\n",
    "    data = pd.DataFrame({'file': path, 'label': [labs-1]})\n",
    "    df = pd.concat([df, data])\n",
    "\n",
    "df.to_csv(\"../data/train/train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/train/a_0000.bin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/train/a_0001.bin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/train/a_0003.bin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/train/a_0004.bin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/train/a_0007.bin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/train/y_0017.bin</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/train/y_0019.bin</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/train/y_0020.bin</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/train/y_0022.bin</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/train/y_0023.bin</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file label\n",
       "0   ./data/train/a_0000.bin     0\n",
       "0   ./data/train/a_0001.bin     0\n",
       "0   ./data/train/a_0003.bin     0\n",
       "0   ./data/train/a_0004.bin     0\n",
       "0   ./data/train/a_0007.bin     0\n",
       "..                      ...   ...\n",
       "0   ./data/train/y_0017.bin    23\n",
       "0   ./data/train/y_0019.bin    23\n",
       "0   ./data/train/y_0020.bin    23\n",
       "0   ./data/train/y_0022.bin    23\n",
       "0   ./data/train/y_0023.bin    23\n",
       "\n",
       "[496 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['file', 'label'])\n",
    "\n",
    "labs = 0\n",
    "prev = []\n",
    "\n",
    "for f in sorted(os.listdir(\"../data/test\")):\n",
    "\n",
    "    label = f.split('_')[0]\n",
    "    \n",
    "    if label not in prev:\n",
    "        prev.append(label)\n",
    "        labs += 1\n",
    "\n",
    "    path = f\"./data/test/{f}\"\n",
    "\n",
    "    data = pd.DataFrame({'file': path, 'label': [labs-1]})\n",
    "    df = pd.concat([df, data])\n",
    "\n",
    "df.to_csv(\"../data/test/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset: 497 items\n",
      "Testset: 214 items\n",
      "-----\n",
      "Total data: 711 items\n"
     ]
    }
   ],
   "source": [
    "trainset = pd.read_csv(\"../data/train_data.csv\")\n",
    "testset = pd.read_csv(\"../data/test_data.csv\")\n",
    "\n",
    "print(f\"Trainset: {len(trainset)} items\")\n",
    "print(f\"Testset: {len(testset)} items\")\n",
    "print('-----')\n",
    "print(f\"Total data: {len(trainset) + len(testset)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
