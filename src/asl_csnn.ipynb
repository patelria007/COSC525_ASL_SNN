{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tonic packages\n",
    "import tonic\n",
    "from tonic import DiskCachedDataset\n",
    "from tonic.dataset import Dataset\n",
    "from tonic.download_utils import extract_archive\n",
    "from tonic.io import make_structured_array\n",
    "\n",
    "# PyTorch packages\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import tonic.transforms as transforms\n",
    "from torch.utils.data import DataLoader #\n",
    "\n",
    "# SNN PyTorch extension packages\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import utils\n",
    "\n",
    "# Visualization packages\n",
    "from IPython.display import HTML \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Other packages\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import os, time\n",
    "from typing import Any, Callable, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLDVS(Dataset):\n",
    "    \"\"\"`ASL-DVS <https://github.com/PIX2NVS/NVS2Graph>`\"\"\"\n",
    "\n",
    "    classes = [chr(letter) for letter in range(97, 123)]  # generate alphabet\n",
    "    int_classes = dict(zip(classes, range(len(classes))))\n",
    "    sensor_size = (240, 180, 2)\n",
    "    dtype = np.dtype([(\"t\", int), (\"x\", int), (\"y\", int), (\"p\", int)])\n",
    "    ordering = dtype.names\n",
    "\n",
    "    def __init__(self, \n",
    "                 save_to: str, \n",
    "                 transform: Optional[Callable] = None,\n",
    "                 target_transform: Optional[Callable] = None,\n",
    "                 transforms: Optional[Callable] = None):\n",
    "        \n",
    "        super().__init__(save_to, transform, target_transform, transforms)\n",
    "\n",
    "        if not self._check_exists():\n",
    "            self.download()\n",
    "            # extract zips within zip\n",
    "            for path, dirs, files in os.walk(self.location_on_system):\n",
    "                dirs.sort()\n",
    "                for file in files:\n",
    "                    if file.startswith(\"Yin\") and file.endswith(\"zip\"):\n",
    "                        extract_archive(os.path.join(self.location_on_system, file))\n",
    "\n",
    "        for path, dirs, files in os.walk(self.location_on_system):\n",
    "            dirs.sort()\n",
    "            files.sort()\n",
    "            for file in files:\n",
    "                if file.endswith(\"mat\"):\n",
    "                    self.data.append(path + \"/\" + file)\n",
    "                    self.targets.append(self.int_classes[path[-1]])\n",
    "\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            (events, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        events, target = scio.loadmat(self.data[index]), self.targets[index]\n",
    "        events = make_structured_array(\n",
    "            events[\"ts\"],\n",
    "            events[\"x\"],\n",
    "            self.sensor_size[1] - 1 - events[\"y\"],\n",
    "            events[\"pol\"],\n",
    "            dtype=self.dtype,\n",
    "        )\n",
    "        if self.transform is not None:\n",
    "            events = self.transform(events)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        if self.transforms is not None:\n",
    "            events, target = self.transforms(events, target)\n",
    "        return events, target\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return (\n",
    "            self._is_file_present()\n",
    "            and self._folder_contains_at_least_n_files_of_type(100800, \".mat\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSNN Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# neuron and simulation parameters\n",
    "spike_grad = surrogate.atan()\n",
    "beta = 0.5\n",
    "\n",
    "#  Initialize Network, 12 filters Conv 5X5-Max Pool 2X2-32 filters Conv 5X5-Max Pool 2X2-800 fully connected 10 o/p\n",
    "net = nn.Sequential(\n",
    "                    # 1st layer\n",
    "                    nn.Conv2d(2, 12, 5),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    # 2nd layer\n",
    "                    nn.Conv2d(12, 32, 5),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    # 3rd Layer\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(32*5*5, 10),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True)\n",
    "                    ).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=2e-2) # Adam optimizer\n",
    "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2) # Mean Square Count Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(net, data):\n",
    "    spk_rec = []\n",
    "    utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
    "\n",
    "    for step in range(data.size(0)):  # data.size(0) = number of time steps\n",
    "        spk_out, mem_out = net(data[step])\n",
    "        spk_rec.append(spk_out)\n",
    "\n",
    "    return torch.stack(spk_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "num_iters = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = []\n",
    "acc_hist = []\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, targets) in enumerate(iter(trainloader)):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        net.train()\n",
    "        spk_rec = forward_pass(net, data)\n",
    "        loss_val = loss_fn(spk_rec, targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        print(f\"Epoch {epoch}, Iteration {i} \\nTrain Loss: {loss_val.item():.2f}\")\n",
    "\n",
    "        acc = SF.accuracy_rate(spk_rec, targets)\n",
    "        acc_hist.append(acc)\n",
    "        print(f\"Accuracy: {acc * 100:.2f}%\\n\")\n",
    "\n",
    "        if i == num_iters:\n",
    "          break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
